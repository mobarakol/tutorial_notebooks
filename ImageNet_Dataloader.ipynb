{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMV+QKn/+EOec0yO8IxB7jD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mobarakol/tutorial_notebooks/blob/main/ImageNet_Dataloader.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ImageNet (ILSVRC2012)\n",
        "\n",
        "It contains 1000 classes, 1.28 million training images, and 50 thousand validation images. There are 1,281,167 images and 732-1300 per class in the ILSVRC2012 training set. This dataset spans 1000 object classes and contains 1,281,167 training images, 50,000 validation images and 100,000 test images. It requires more than 150GB of storage, and training a resnet50 on it will take around 215 hours using a T4 GPU on Google Colab. Folder name to actual class mapping: https://www.image-net.org/challenges/LSVRC/2012/browse-synsets.php <br>\n",
        "Sample size is not equal in ImageNet. For example top 10 classes:<br>\n",
        "n02094433:    3047 (Yorkshire terrier)<br>\n",
        "n02086240:    2563 (Shih-Tzu)<br>\n",
        "n01882714:    2469 (koala bear, kangaroo bear, native bear, )<br>\n",
        "n02087394:    2449 (Rhodesian ridgeback)<br>\n",
        "n02100735:    2426 (English setter)<br>\n",
        "n00483313:    2410 (singles)<br>\n",
        "n02279972:    2386 (monarch butterfly, Danaus plexippus)<br>\n",
        "n09428293:    2382 (seashore)<br>\n",
        "n02138441:    2341 (meerkat)<br>\n",
        "n02100583:    2334 (vizsla, Hungarian pointer)<br>\n",
        "\n",
        "\n",
        "Task-1. Image classification (2010-2014): Algorithms produce a list of object categories present in the image.<br>\n",
        "Task-2. Single-object localization (2011-2014): Algorithms\n",
        "produce a list of object categories present in the image, along with an axis-aligned bounding box indicating the position and scale of one instance of each object category.<br>\n",
        "Task-3. Object detection (2013-2014): Algorithms produce\n",
        "a list of object categories present in the image along\n",
        "with an axis-aligned bounding box indicating the\n",
        "position and scale of every instance of each object\n",
        "category.<br>\n",
        "\n",
        "#Download Links:\n",
        "\n",
        "Training Images (taskl&2): https://image-net.org/data/ILSVRC/2012/ILSVRC2012_img_train.tar <br>\n",
        "Training Annotations (taskl&2): https://image-net.org/data/ILSVRC/2012/ILSVRC2012_bbox_train_v2.tar.gz <br>\n",
        "\n",
        "Validation Images (all tasks): https://image-net.org/data/ILSVRC/2012/ILSVRC2012_img_val.tar\n",
        "\n",
        "Validation Annotations (all tasks): https://image-net.org/data/ILSVRC/2012/ILSVRC2012_bbox_val_v3.tgz\n"
      ],
      "metadata": {
        "id": "KHwLWpzQGmJA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preparing Train Images into Folders (Not using in this tutorial)\n",
        "src: https://github.com/pytorch/examples/blob/main/imagenet/extract_ILSVRC.sh"
      ],
      "metadata": {
        "id": "qtbN1219glYr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create train directory; move .tar file; change directory\n",
        "!mkdir imagenet/train && mv ILSVRC2012_img_train.tar imagenet/train/ && cd imagenet/train\n",
        "# Extract training set; remove compressed file\n",
        "!tar -xvf ILSVRC2012_img_train.tar && rm -f ILSVRC2012_img_train.tar\n",
        "#\n",
        "# At this stage imagenet/train will contain 1000 compressed .tar files, one for each category\n",
        "#\n",
        "# For each .tar file: \n",
        "#   1. create directory with same name as .tar file\n",
        "#   2. extract and copy contents of .tar file into directory\n",
        "#   3. remove .tar file\n",
        "!find . -name \"*.tar\" | while read NAME ; do mkdir -p \"${NAME%.tar}\"; tar -xvf \"${NAME}\" -C \"${NAME%.tar}\"; rm -f \"${NAME}\"; done"
      ],
      "metadata": {
        "id": "piDwRwOIgkQF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Download only Validation Set"
      ],
      "metadata": {
        "id": "2SlLraVFT635"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://image-net.org/data/ILSVRC/2012/ILSVRC2012_img_val.tar"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6YlcVUkDc1on",
        "outputId": "d4bc00aa-3087-4413-c75a-48a29437c08b"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-10-05 18:40:55--  https://image-net.org/data/ILSVRC/2012/ILSVRC2012_img_val.tar\n",
            "Resolving image-net.org (image-net.org)... 171.64.68.16\n",
            "Connecting to image-net.org (image-net.org)|171.64.68.16|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 6744924160 (6.3G) [application/x-tar]\n",
            "Saving to: ‘ILSVRC2012_img_val.tar’\n",
            "\n",
            "ILSVRC2012_img_val. 100%[===================>]   6.28G  38.2MB/s    in 2m 58s  \n",
            "\n",
            "2022-10-05 18:43:53 (36.2 MB/s) - ‘ILSVRC2012_img_val.tar’ saved [6744924160/6744924160]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preparing Valid Images into Folders"
      ],
      "metadata": {
        "id": "wbsK_wL6g6RA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir imagenet\n",
        "!mkdir imagenet/val\n",
        "!tar -xvf ILSVRC2012_img_val.tar --directory imagenet/val\n",
        "%cd imagenet/val\n",
        "!wget -qO- https://raw.githubusercontent.com/soumith/imagenetloader.torch/master/valprep.sh | bash\n",
        "%cd ../.."
      ],
      "metadata": {
        "id": "4_XdkO8Tc-13"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import argparse\n",
        "import os\n",
        "import shutil\n",
        "import time\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.parallel\n",
        "import torch.backends.cudnn as cudnn\n",
        "import torch.distributed as dist\n",
        "import torch.optim\n",
        "import torch.utils.data\n",
        "import torch.utils.data.distributed\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.datasets as datasets\n",
        "import torchvision.models as models\n",
        "\n",
        "valdir = os.path.join('imagenet', 'val')\n",
        "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                                    std=[0.229, 0.224, 0.225])\n",
        "\n",
        "\n",
        "val_dataset = datasets.ImageFolder(valdir, transforms.Compose([\n",
        "        transforms.Resize(256),\n",
        "        transforms.CenterCrop(224),\n",
        "        transforms.ToTensor(),\n",
        "        normalize,\n",
        "    ]))\n",
        "val_loader = torch.utils.data.DataLoader(\n",
        "    val_dataset,\n",
        "    batch_size=32, shuffle=False,\n",
        "    num_workers=2, pin_memory=True)\n",
        "\n",
        "for i, (input, target) in enumerate(val_loader):\n",
        "    print(input.shape, target)\n",
        "    break\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G9hFROHsZRxQ",
        "outputId": "44fccc6f-3e23-4552-c692-ebffa205439e"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([32, 3, 224, 224]) tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cDj0Q7bjf08m"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}