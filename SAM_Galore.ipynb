{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMuojcUp/2BOMCyn78l2Q8J",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mobarakol/tutorial_notebooks/blob/main/SAM_Galore.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t-lxeldRfn1F",
        "outputId": "f4a736e2-6933-41d2-8712-601905b47eca"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for segment_anything (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "--2025-06-28 17:05:28--  http://wget/\n",
            "Resolving wget (wget)... failed: Name or service not known.\n",
            "wget: unable to resolve host address ‘wget’\n",
            "--2025-06-28 17:05:28--  https://dl.fbaipublicfiles.com/segment_anything/sam_vit_b_01ec64.pth\n",
            "Resolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 13.227.219.59, 13.227.219.10, 13.227.219.33, ...\n",
            "Connecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|13.227.219.59|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 375042383 (358M) [binary/octet-stream]\n",
            "Saving to: ‘sam_vit_b_01ec64.pth’\n",
            "\n",
            "sam_vit_b_01ec64.pt 100%[===================>] 357.67M  7.54MB/s    in 5.8s    \n",
            "\n",
            "2025-06-28 17:05:34 (61.4 MB/s) - ‘sam_vit_b_01ec64.pth’ saved [375042383/375042383]\n",
            "\n",
            "FINISHED --2025-06-28 17:05:34--\n",
            "Total wall clock time: 5.9s\n",
            "Downloaded: 1 files, 358M in 5.8s (61.4 MB/s)\n"
          ]
        }
      ],
      "source": [
        "!pip -q install git+https://github.com/facebookresearch/segment-anything.git\n",
        "!wget wget https://dl.fbaipublicfiles.com/segment_anything/sam_vit_b_01ec64.pth"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from segment_anything import sam_model_registry\n",
        "\n",
        "sam = sam_model_registry[\"vit_b\"](\n",
        "    checkpoint=\"sam_vit_b_01ec64.pth\")\n",
        "sam_encoder = sam.image_encoder"
      ],
      "metadata": {
        "id": "8t7V7GvIf8RD"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SVD Galore from Scratch:"
      ],
      "metadata": {
        "id": "im-x-SrxhMiU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip -q install tensorly"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mi7jCs6OjlD7",
        "outputId": "520f6f3e-97fd-4b54-d44c-cf1cbdcc8270"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/7.4 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/7.4 MB\u001b[0m \u001b[31m69.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/7.4 MB\u001b[0m \u001b[31m31.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m7.4/7.4 MB\u001b[0m \u001b[31m76.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.4/7.4 MB\u001b[0m \u001b[31m57.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# copy dependencies from transformers/optimization.py\n",
        "import math\n",
        "import warnings\n",
        "from typing import Callable, Iterable, Tuple\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.optim import Optimizer\n",
        "\n",
        "from transformers.utils.versions import require_version\n",
        "\n",
        "# from .galore_projector import GaLoreProjector\n",
        "# from .galore_projector_tensor import GaLoreProjectorTensor\n",
        "import torch\n",
        "\n",
        "class GaLoreProjector:\n",
        "    def __init__(self, rank, verbose=False, update_proj_gap=200, scale=1.0, proj_type='std'):\n",
        "        self.rank = rank\n",
        "        self.verbose = verbose\n",
        "        self.update_proj_gap = update_proj_gap\n",
        "        self.scale = scale\n",
        "        self.ortho_matrix = None\n",
        "        self.proj_type = proj_type\n",
        "\n",
        "    def project(self, full_rank_grad, iter):\n",
        "        if self.proj_type == 'std':\n",
        "            if full_rank_grad.shape[0] >= full_rank_grad.shape[1]:\n",
        "                if self.ortho_matrix is None or iter % self.update_proj_gap == 0:\n",
        "                    self.ortho_matrix = self.get_orthogonal_matrix(full_rank_grad, self.rank, type='right')\n",
        "                low_rank_grad = torch.matmul(full_rank_grad, self.ortho_matrix.t().to(full_rank_grad.device.type))\n",
        "            else:\n",
        "                if self.ortho_matrix is None or iter % self.update_proj_gap == 0:\n",
        "                    self.ortho_matrix = self.get_orthogonal_matrix(full_rank_grad, self.rank, type='left')\n",
        "                low_rank_grad = torch.matmul(self.ortho_matrix.t().to(full_rank_grad.device.type), full_rank_grad)\n",
        "        elif self.proj_type == 'reverse_std':\n",
        "            if full_rank_grad.shape[0] >= full_rank_grad.shape[1]:\n",
        "                if self.ortho_matrix is None or iter % self.update_proj_gap == 0:\n",
        "                    self.ortho_matrix = self.get_orthogonal_matrix(full_rank_grad, self.rank, type='left')\n",
        "                low_rank_grad = torch.matmul(self.ortho_matrix.t().to(full_rank_grad.device.type),full_rank_grad)\n",
        "            else:\n",
        "                if self.ortho_matrix is None or iter % self.update_proj_gap == 0:\n",
        "                    self.ortho_matrix = self.get_orthogonal_matrix(full_rank_grad, self.rank, type='right')\n",
        "                low_rank_grad = torch.matmul(full_rank_grad,self.ortho_matrix.t().to(full_rank_grad.device.type))\n",
        "        elif self.proj_type == 'right':\n",
        "            if self.ortho_matrix is None or iter % self.update_proj_gap == 0:\n",
        "                self.ortho_matrix = self.get_orthogonal_matrix(full_rank_grad, self.rank, type='right')\n",
        "            low_rank_grad = torch.matmul(full_rank_grad, self.ortho_matrix.t().to(full_rank_grad.device.type))\n",
        "        elif self.proj_type == 'left':\n",
        "            if self.ortho_matrix is None or iter % self.update_proj_gap == 0:\n",
        "                self.ortho_matrix = self.get_orthogonal_matrix(full_rank_grad, self.rank, type='left')\n",
        "            low_rank_grad = torch.matmul(self.ortho_matrix.t().to(full_rank_grad.device.type), full_rank_grad)\n",
        "        elif self.proj_type == 'full':\n",
        "            if self.ortho_matrix is None or iter % self.update_proj_gap == 0:\n",
        "                self.ortho_matrix = self.get_orthogonal_matrix(full_rank_grad, self.rank, type='full')\n",
        "            low_rank_grad = torch.matmul(self.ortho_matrix[0].t().to(full_rank_grad.device.type), full_rank_grad) @ self.ortho_matrix[1].t().to(full_rank_grad.device.type)\n",
        "\n",
        "        return low_rank_grad\n",
        "\n",
        "    def project_back(self, low_rank_grad):\n",
        "        if self.proj_type == 'std':\n",
        "            if low_rank_grad.shape[0] >= low_rank_grad.shape[1]:\n",
        "                full_rank_grad = torch.matmul(low_rank_grad, self.ortho_matrix.to(low_rank_grad.device.type))\n",
        "            else:\n",
        "                full_rank_grad = torch.matmul(self.ortho_matrix.to(low_rank_grad.device.type), low_rank_grad)\n",
        "        elif self.proj_type == 'reverse_std':\n",
        "            if low_rank_grad.shape[0] <= low_rank_grad.shape[1]: # note this is different from std\n",
        "                full_rank_grad = torch.matmul(self.ortho_matrix.to(low_rank_grad.device.type), low_rank_grad)\n",
        "            else:\n",
        "                full_rank_grad = torch.matmul(low_rank_grad, self.ortho_matrix.to(low_rank_grad.device.type))\n",
        "        elif self.proj_type == 'right':\n",
        "            full_rank_grad = torch.matmul(low_rank_grad, self.ortho_matrix.to(low_rank_grad.device.type))\n",
        "        elif self.proj_type == 'left':\n",
        "            full_rank_grad = torch.matmul(self.ortho_matrix.to(low_rank_grad.device.type), low_rank_grad)\n",
        "        elif self.proj_type == 'full':\n",
        "            full_rank_grad = torch.matmul(self.ortho_matrix[0].to(low_rank_grad.device.type), low_rank_grad) @ self.ortho_matrix[1].to(low_rank_grad.device.type)\n",
        "\n",
        "\n",
        "        return full_rank_grad * self.scale\n",
        "\n",
        "\n",
        "    # svd decomposition\n",
        "    def get_orthogonal_matrix(self, weights, rank, type):\n",
        "        module_params = weights\n",
        "\n",
        "        if module_params.data.dtype != torch.float:\n",
        "            float_data = False\n",
        "            original_type = module_params.data.dtype\n",
        "            original_device = module_params.data.device\n",
        "            matrix = module_params.data.float()\n",
        "        else:\n",
        "            float_data = True\n",
        "            matrix = module_params.data\n",
        "\n",
        "        U, s, Vh = torch.linalg.svd(matrix, full_matrices = False)\n",
        "\n",
        "        #make the smaller matrix always to be orthogonal matrix\n",
        "        if type=='right':\n",
        "            B = Vh[:rank, :]\n",
        "            if not float_data:\n",
        "                B = B.to(original_device).type(original_type)\n",
        "            return B\n",
        "        elif type=='left':\n",
        "            A = U[:, :rank]\n",
        "            if not float_data:\n",
        "                A = A.to(original_device).type(original_type)\n",
        "            return A\n",
        "        elif type=='full':\n",
        "            A = U[:, :rank]\n",
        "            B = Vh[:rank, :]\n",
        "            if not float_data:\n",
        "                A = A.to(original_device).type(original_type)\n",
        "                B = B.to(original_device).type(original_type)\n",
        "            return [A, B]\n",
        "        else:\n",
        "            raise ValueError('type should be left, right or full')\n",
        "\n",
        "\n",
        "import torch\n",
        "from tensorly.decomposition import tucker\n",
        "from tensorly import tenalg\n",
        "\n",
        "# The GaLoreProjector class in Python implements a projection method using orthogonal matrix\n",
        "# decomposition for low-rank approximation of gradients for general tensors of dimension >2.\n",
        "# We use tensor decomposition using tensorly library: https://tensorly.org/stable/index.html\n",
        "class GaLoreProjectorTensor:\n",
        "    \"\"\"\n",
        "    A class that represents a projector for the GaLore algorithm.\n",
        "\n",
        "    Args:\n",
        "        rank (int): The rank of the projector.\n",
        "        verbose (bool, optional): Whether to print verbose output. Defaults to False.\n",
        "        update_proj_gap (int, optional): The number of iterations between updating the orthogonal matrix. Defaults to 200.\n",
        "        scale (float, optional): The scaling factor for the projected gradients. Defaults to 1.0.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, rank, verbose=False, update_proj_gap=200, scale=1.0):\n",
        "        self.rank = rank\n",
        "        self.verbose = verbose\n",
        "        self.update_proj_gap = update_proj_gap\n",
        "        self.scale = scale\n",
        "        self.ortho_matrix = None\n",
        "        self.transformed_low_rank = None\n",
        "\n",
        "    def project(self, full_rank_grad, iter):\n",
        "        \"\"\"\n",
        "        Projects the full-rank gradients onto the low-rank subspace.\n",
        "\n",
        "        Args:\n",
        "            full_rank_grad (torch.Tensor): The full-rank gradients.\n",
        "            iter (int): The current iteration.\n",
        "\n",
        "        Returns:\n",
        "            torch.Tensor: The transformed low-rank gradients.\n",
        "        \"\"\"\n",
        "        if self.ortho_matrix is None and iter % self.update_proj_gap == 0:\n",
        "            self.ortho_matrix = self.get_orthogonal_matrix(full_rank_grad, self.rank)\n",
        "        self.transformed_low_rank = self.transform(self.ortho_matrix, full_rank_grad)\n",
        "        return self.transformed_low_rank\n",
        "\n",
        "    def project_back(self, low_rank_grad):\n",
        "        \"\"\"\n",
        "        Projects the low-rank gradients back to the full-rank space.\n",
        "\n",
        "        Args:\n",
        "            low_rank_grad (torch.Tensor): The low-rank gradients.\n",
        "\n",
        "        Returns:\n",
        "            torch.Tensor: The full-rank gradients.\n",
        "        \"\"\"\n",
        "        full_rank_grad = self.inverse_transform(self.ortho_matrix, self.transformed_low_rank)\n",
        "        return full_rank_grad * self.scale\n",
        "\n",
        "    # svd decomposition\n",
        "    def get_orthogonal_matrix(self, weights, rank_all):\n",
        "        \"\"\"\n",
        "        Computes the orthogonal matrix using SVD decomposition.\n",
        "\n",
        "        Args:\n",
        "            weights (torch.Tensor): The weights to decompose.\n",
        "            rank_all (int): The desired rank of the decomposition.\n",
        "\n",
        "        Returns:\n",
        "            tuple: A tuple containing the core and factors of the orthogonal matrix.\n",
        "        \"\"\"\n",
        "        module_params = weights\n",
        "        if module_params.data.dtype != torch.float:\n",
        "            matrix = module_params.data.float()\n",
        "        else:\n",
        "            matrix = module_params.data\n",
        "        tucker_tensor = tucker(matrix, rank=rank_all)\n",
        "        return tucker_tensor\n",
        "\n",
        "    def transform(self, tensor, x):\n",
        "        \"\"\"\n",
        "        Transforms the input tensor using the factors of the orthogonal matrix.\n",
        "\n",
        "        Args:\n",
        "            tensor (tuple): A tuple containing the core and factors of the orthogonal matrix.\n",
        "            x (torch.Tensor): The input tensor.\n",
        "\n",
        "        Returns:\n",
        "            torch.Tensor: The transformed tensor.\n",
        "        \"\"\"\n",
        "        _, factors = tensor\n",
        "        return tenalg.multi_mode_dot(x, factors, transpose=True)\n",
        "\n",
        "    def inverse_transform(self, tensor, x):\n",
        "        \"\"\"\n",
        "        Inverse transforms the input tensor using the factors of the orthogonal matrix.\n",
        "\n",
        "        Args:\n",
        "            tensor (tuple): A tuple containing the core and factors of the orthogonal matrix.\n",
        "            x (torch.Tensor): The input tensor.\n",
        "\n",
        "        Returns:\n",
        "            torch.Tensor: The inverse transformed tensor.\n",
        "        \"\"\"\n",
        "        _, factors = tensor\n",
        "        return tenalg.multi_mode_dot(x, factors)\n",
        "\n",
        "\n",
        "\n",
        "class GaLoreAdamW(Optimizer):\n",
        "    \"\"\"\n",
        "    Implements Adam algorithm with weight decay fix as introduced in [Decoupled Weight Decay\n",
        "    Regularization](https://arxiv.org/abs/1711.05101).\n",
        "\n",
        "    Parameters:\n",
        "        params (`Iterable[nn.parameter.Parameter]`):\n",
        "            Iterable of parameters to optimize or dictionaries defining parameter groups.\n",
        "        lr (`float`, *optional*, defaults to 0.001):\n",
        "            The learning rate to use.\n",
        "        betas (`Tuple[float,float]`, *optional*, defaults to `(0.9, 0.999)`):\n",
        "            Adam's betas parameters (b1, b2).\n",
        "        eps (`float`, *optional*, defaults to 1e-06):\n",
        "            Adam's epsilon for numerical stability.\n",
        "        weight_decay (`float`, *optional*, defaults to 0.0):\n",
        "            Decoupled weight decay to apply.\n",
        "        correct_bias (`bool`, *optional*, defaults to `True`):\n",
        "            Whether or not to correct bias in Adam (for instance, in Bert TF repository they use `False`).\n",
        "        no_deprecation_warning (`bool`, *optional*, defaults to `False`):\n",
        "            A flag used to disable the deprecation warning (set to `True` to disable the warning).\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        params: Iterable[nn.parameter.Parameter],\n",
        "        lr: float = 1e-3,\n",
        "        betas: Tuple[float, float] = (0.9, 0.999),\n",
        "        eps: float = 1e-6,\n",
        "        weight_decay: float = 0.0,\n",
        "        correct_bias: bool = True,\n",
        "        no_deprecation_warning: bool = False,\n",
        "    ):\n",
        "        if not no_deprecation_warning:\n",
        "            warnings.warn(\n",
        "                \"This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch\"\n",
        "                \" implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this\"\n",
        "                \" warning\",\n",
        "                FutureWarning,\n",
        "            )\n",
        "        require_version(\"torch>=1.5.0\")  # add_ with alpha\n",
        "        if lr < 0.0:\n",
        "            raise ValueError(f\"Invalid learning rate: {lr} - should be >= 0.0\")\n",
        "        if not 0.0 <= betas[0] < 1.0:\n",
        "            raise ValueError(f\"Invalid beta parameter: {betas[0]} - should be in [0.0, 1.0)\")\n",
        "        if not 0.0 <= betas[1] < 1.0:\n",
        "            raise ValueError(f\"Invalid beta parameter: {betas[1]} - should be in [0.0, 1.0)\")\n",
        "        if not 0.0 <= eps:\n",
        "            raise ValueError(f\"Invalid epsilon value: {eps} - should be >= 0.0\")\n",
        "        defaults = {\"lr\": lr, \"betas\": betas, \"eps\": eps, \"weight_decay\": weight_decay, \"correct_bias\": correct_bias}\n",
        "        super().__init__(params, defaults)\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def step(self, closure: Callable = None):\n",
        "        \"\"\"\n",
        "        Performs a single optimization step.\n",
        "\n",
        "        Arguments:\n",
        "            closure (`Callable`, *optional*): A closure that reevaluates the model and returns the loss.\n",
        "        \"\"\"\n",
        "        loss = None\n",
        "        if closure is not None:\n",
        "            loss = closure()\n",
        "\n",
        "        for group in self.param_groups:\n",
        "            for p in group[\"params\"]:\n",
        "                if p.grad is None:\n",
        "                    continue\n",
        "                grad = p.grad\n",
        "                if grad.is_sparse:\n",
        "                    raise RuntimeError(\"Adam does not support sparse gradients, please consider SparseAdam instead\")\n",
        "\n",
        "                state = self.state[p]\n",
        "\n",
        "                if \"step\" not in state:\n",
        "                    state[\"step\"] = 0\n",
        "\n",
        "                if 'dim' not in group:\n",
        "                    group['dim'] = 2\n",
        "\n",
        "                # GaLore Projection\n",
        "                if \"rank\" in group:\n",
        "                    if \"projector\" not in state:\n",
        "                        if group['dim'] <=2:\n",
        "                            state[\"projector\"] = GaLoreProjector(group[\"rank\"], update_proj_gap=group[\"update_proj_gap\"], scale=group[\"scale\"], proj_type=group[\"proj_type\"])\n",
        "                        else:\n",
        "                            state[\"projector\"] = GaLoreProjectorTensor(group[\"rank\"], update_proj_gap=group[\"update_proj_gap\"], scale=group[\"scale\"], proj_type=group[\"proj_type\"])\n",
        "                    grad = state[\"projector\"].project(grad, state[\"step\"])\n",
        "\n",
        "                # State initialization\n",
        "                if \"exp_avg\" not in state:\n",
        "                    # Exponential moving average of gradient values\n",
        "                    state[\"exp_avg\"] = torch.zeros_like(grad)\n",
        "                    # Exponential moving average of squared gradient values\n",
        "                    state[\"exp_avg_sq\"] = torch.zeros_like(grad)\n",
        "\n",
        "                exp_avg, exp_avg_sq = state[\"exp_avg\"], state[\"exp_avg_sq\"]\n",
        "                beta1, beta2 = group[\"betas\"]\n",
        "\n",
        "                state[\"step\"] += 1\n",
        "\n",
        "                # Decay the first and second moment running average coefficient\n",
        "                # In-place operations to update the averages at the same time\n",
        "                exp_avg.mul_(beta1).add_(grad, alpha=(1.0 - beta1))\n",
        "                exp_avg_sq.mul_(beta2).addcmul_(grad, grad, value=1.0 - beta2)\n",
        "                denom = exp_avg_sq.sqrt().add_(group[\"eps\"])\n",
        "\n",
        "                step_size = group[\"lr\"]\n",
        "                if group[\"correct_bias\"]:  # No bias correction for Bert\n",
        "                    bias_correction1 = 1.0 - beta1 ** state[\"step\"]\n",
        "                    bias_correction2 = 1.0 - beta2 ** state[\"step\"]\n",
        "                    step_size = step_size * math.sqrt(bias_correction2) / bias_correction1\n",
        "\n",
        "                # compute norm gradient\n",
        "                norm_grad = exp_avg / denom\n",
        "\n",
        "                # GaLore Projection Back\n",
        "                if \"rank\" in group:\n",
        "                    norm_grad = state[\"projector\"].project_back(norm_grad)\n",
        "\n",
        "                p.add_(norm_grad, alpha=-step_size)\n",
        "\n",
        "                # Just adding the square of the weights to the loss function is *not*\n",
        "                # the correct way of using L2 regularization/weight decay with Adam,\n",
        "                # since that will interact with the m and v parameters in strange ways.\n",
        "                #\n",
        "                # Instead we want to decay the weights in a manner that doesn't interact\n",
        "                # with the m/v parameters. This is equivalent to adding the square\n",
        "                # of the weights to the loss with plain (non-momentum) SGD.\n",
        "                # Add weight decay at the end (fixed version)\n",
        "                if group[\"weight_decay\"] > 0.0:\n",
        "                    p.add_(p, alpha=(-group[\"lr\"] * group[\"weight_decay\"]))\n",
        "\n",
        "        return loss\n"
      ],
      "metadata": {
        "id": "wsvxL9-YhFrK"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Apply SVD Galore on SAM:"
      ],
      "metadata": {
        "id": "jbN8JIL0hcRI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import DepthAnythingForDepthEstimation, AutoImageProcessor\n",
        "from segment_anything import sam_model_registry\n",
        "from torch import nn\n",
        "\n",
        "class D2GPLand(nn.Module):\n",
        "    def __init__(self,\n",
        "                 height=256,\n",
        "                 width=480,\n",
        "                 num_classes=4):\n",
        "        super(D2GPLand, self).__init__()\n",
        "\n",
        "        sam = sam_model_registry[\"vit_b\"](\n",
        "            checkpoint=\"sam_vit_b_01ec64.pth\")\n",
        "\n",
        "        self.sam_encoder = sam.image_encoder\n",
        "\n",
        "\n",
        "        # initialize DA2 encoder\n",
        "        model_name = \"depth-anything/Depth-Anything-V2-Small-hf\"\n",
        "        self.da2_processor = AutoImageProcessor.from_pretrained(model_name)\n",
        "        da2_model = DepthAnythingForDepthEstimation.from_pretrained(model_name)\n",
        "        self.da2_encoder = da2_model.backbone\n",
        "        # freeze the DA2 encoder\n",
        "        for param in self.da2_encoder.parameters():\n",
        "            param.requires_grad = False\n",
        "        self.useless_conv = nn.Conv2d(in_channels=384, out_channels=256, kernel_size=1)\n",
        "\n",
        "    def forward(self, image):\n",
        "        outs = self.sam_encoder(image)\n",
        "        return outs\n"
      ],
      "metadata": {
        "id": "eEI277Q1hz4u"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Version-1: not freezing non target layer of SAM encoder as Galore"
      ],
      "metadata": {
        "id": "_vXqCHb0nzx3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = D2GPLand()\n",
        "# make parameters with \"rank\" to a single group, if param_name has \"mlp\" or \"attn\"\n",
        "galore_params = []\n",
        "target_modules_list=[\"attn.qkv\", \"attn.proj\"]\n",
        "for module_name, module in model.named_modules():\n",
        "    if not isinstance(module, nn.Linear):\n",
        "        continue\n",
        "\n",
        "    if not any(target_key in module_name for target_key in target_modules_list):\n",
        "        continue\n",
        "\n",
        "    # print('enable GaLore for weights in module: ', module_name)\n",
        "    print('Adaptatation Module:', module_name, module)\n",
        "    galore_params.append(module.weight)\n",
        "id_galore_params = [id(p) for p in galore_params]\n",
        "\n",
        "# make parameters without \"rank\" to another group\n",
        "regular_params = [p for p in model.parameters() if id(p) not in id_galore_params]\n",
        "\n",
        "# then call galore_adamw\n",
        "param_groups = [{'params': regular_params},\n",
        "                {'params': galore_params, 'rank': 128, 'update_proj_gap': 50, 'scale': 1, 'proj_type': \"std\"}]\n",
        "\n",
        "\n",
        "optimizer = GaLoreAdamW(param_groups, lr=1e-5, weight_decay=0.0)\n",
        "\n",
        "#Calculate total trainable param:\n",
        "total_trainable_params = 0\n",
        "for p in model.parameters():\n",
        "    if p.requires_grad:\n",
        "        total_trainable_params += p.numel()\n",
        "print(f\"\\nTotal trainable parameters in the model: {total_trainable_params / 1e6:.2f}M\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fbkox1wpnvDQ",
        "outputId": "7710fb21-8f4c-4aaf-d46b-bfef3246a63d"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Adaptatation Module: sam_encoder.blocks.0.attn.qkv Linear(in_features=768, out_features=2304, bias=True)\n",
            "Adaptatation Module: sam_encoder.blocks.0.attn.proj Linear(in_features=768, out_features=768, bias=True)\n",
            "Adaptatation Module: sam_encoder.blocks.1.attn.qkv Linear(in_features=768, out_features=2304, bias=True)\n",
            "Adaptatation Module: sam_encoder.blocks.1.attn.proj Linear(in_features=768, out_features=768, bias=True)\n",
            "Adaptatation Module: sam_encoder.blocks.2.attn.qkv Linear(in_features=768, out_features=2304, bias=True)\n",
            "Adaptatation Module: sam_encoder.blocks.2.attn.proj Linear(in_features=768, out_features=768, bias=True)\n",
            "Adaptatation Module: sam_encoder.blocks.3.attn.qkv Linear(in_features=768, out_features=2304, bias=True)\n",
            "Adaptatation Module: sam_encoder.blocks.3.attn.proj Linear(in_features=768, out_features=768, bias=True)\n",
            "Adaptatation Module: sam_encoder.blocks.4.attn.qkv Linear(in_features=768, out_features=2304, bias=True)\n",
            "Adaptatation Module: sam_encoder.blocks.4.attn.proj Linear(in_features=768, out_features=768, bias=True)\n",
            "Adaptatation Module: sam_encoder.blocks.5.attn.qkv Linear(in_features=768, out_features=2304, bias=True)\n",
            "Adaptatation Module: sam_encoder.blocks.5.attn.proj Linear(in_features=768, out_features=768, bias=True)\n",
            "Adaptatation Module: sam_encoder.blocks.6.attn.qkv Linear(in_features=768, out_features=2304, bias=True)\n",
            "Adaptatation Module: sam_encoder.blocks.6.attn.proj Linear(in_features=768, out_features=768, bias=True)\n",
            "Adaptatation Module: sam_encoder.blocks.7.attn.qkv Linear(in_features=768, out_features=2304, bias=True)\n",
            "Adaptatation Module: sam_encoder.blocks.7.attn.proj Linear(in_features=768, out_features=768, bias=True)\n",
            "Adaptatation Module: sam_encoder.blocks.8.attn.qkv Linear(in_features=768, out_features=2304, bias=True)\n",
            "Adaptatation Module: sam_encoder.blocks.8.attn.proj Linear(in_features=768, out_features=768, bias=True)\n",
            "Adaptatation Module: sam_encoder.blocks.9.attn.qkv Linear(in_features=768, out_features=2304, bias=True)\n",
            "Adaptatation Module: sam_encoder.blocks.9.attn.proj Linear(in_features=768, out_features=768, bias=True)\n",
            "Adaptatation Module: sam_encoder.blocks.10.attn.qkv Linear(in_features=768, out_features=2304, bias=True)\n",
            "Adaptatation Module: sam_encoder.blocks.10.attn.proj Linear(in_features=768, out_features=768, bias=True)\n",
            "Adaptatation Module: sam_encoder.blocks.11.attn.qkv Linear(in_features=768, out_features=2304, bias=True)\n",
            "Adaptatation Module: sam_encoder.blocks.11.attn.proj Linear(in_features=768, out_features=768, bias=True)\n",
            "\n",
            "Total trainable parameters in the model: 89.77M\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-8-1865894499.py:256: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Version-2: freezing non target layer of SAM encoder"
      ],
      "metadata": {
        "id": "IcESm11vwE0W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = D2GPLand()\n",
        "# make parameters with \"rank\" to a single group, if param_name has \"mlp\" or \"attn\"\n",
        "\n",
        "target_modules_list=[\"attn.qkv\", \"attn.proj\"]\n",
        "galore_params = []\n",
        "id_galore_params = []\n",
        "\n",
        "# Step 1: Freeze all non-target modules in SAM encoder, and collect all trainable GaLore params\n",
        "for module_name, module in model.sam_encoder.named_modules():\n",
        "    if isinstance(module, nn.Linear) and any(t in module_name for t in target_modules_list):\n",
        "        print(\"Adaptation Module (GaLore):\", module_name)\n",
        "        for param in module.parameters():\n",
        "            param.requires_grad = True  # Make target modules trainable\n",
        "            galore_params.append(param)  # Collect all trainable params (weights + biases)\n",
        "            id_galore_params.append(id(param))\n",
        "    else:\n",
        "        # Freeze all non-target SAM encoder modules\n",
        "        for param in module.parameters():\n",
        "            param.requires_grad = False\n",
        "\n",
        "\n",
        "# Step 2: Collect regular (non-GaLore) parameters from rest of the model\n",
        "regular_params = [p for p in model.parameters() if p.requires_grad and id(p) not in id_galore_params]\n",
        "\n",
        "# then call galore_adamw\n",
        "param_groups = [{'params': regular_params},\n",
        "                {'params': galore_params, 'rank': 128, 'update_proj_gap': 50, 'scale': 1, 'proj_type': \"std\"}]\n",
        "\n",
        "\n",
        "optimizer = GaLoreAdamW(param_groups, lr=1e-5, weight_decay=0.0)\n",
        "\n",
        "# Optional: Count and print number of trainable parameters\n",
        "total_trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "print(f\"\\n✅ Total trainable parameters: {total_trainable_params / 1e6:.2f}M\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zq61PeXwtVdg",
        "outputId": "184ab9f9-1a52-490c-ea91-5a78414be874"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Adaptation Module (GaLore): blocks.0.attn.qkv\n",
            "Adaptation Module (GaLore): blocks.0.attn.proj\n",
            "Adaptation Module (GaLore): blocks.1.attn.qkv\n",
            "Adaptation Module (GaLore): blocks.1.attn.proj\n",
            "Adaptation Module (GaLore): blocks.2.attn.qkv\n",
            "Adaptation Module (GaLore): blocks.2.attn.proj\n",
            "Adaptation Module (GaLore): blocks.3.attn.qkv\n",
            "Adaptation Module (GaLore): blocks.3.attn.proj\n",
            "Adaptation Module (GaLore): blocks.4.attn.qkv\n",
            "Adaptation Module (GaLore): blocks.4.attn.proj\n",
            "Adaptation Module (GaLore): blocks.5.attn.qkv\n",
            "Adaptation Module (GaLore): blocks.5.attn.proj\n",
            "Adaptation Module (GaLore): blocks.6.attn.qkv\n",
            "Adaptation Module (GaLore): blocks.6.attn.proj\n",
            "Adaptation Module (GaLore): blocks.7.attn.qkv\n",
            "Adaptation Module (GaLore): blocks.7.attn.proj\n",
            "Adaptation Module (GaLore): blocks.8.attn.qkv\n",
            "Adaptation Module (GaLore): blocks.8.attn.proj\n",
            "Adaptation Module (GaLore): blocks.9.attn.qkv\n",
            "Adaptation Module (GaLore): blocks.9.attn.proj\n",
            "Adaptation Module (GaLore): blocks.10.attn.qkv\n",
            "Adaptation Module (GaLore): blocks.10.attn.proj\n",
            "Adaptation Module (GaLore): blocks.11.attn.qkv\n",
            "Adaptation Module (GaLore): blocks.11.attn.proj\n",
            "\n",
            "✅ Total trainable parameters: 28.45M\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-8-1865894499.py:256: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    }
  ]
}